trg = apply(Y, 1, function(r) {
which.max(r) - 1
})
e = which(prd != trg)
e.pick = sample(e, size = 9)
plot(1:100,1:100, type='n', axes=FALSE, xlab='', ylab='', ylim=c(100,0) )
for( i in 0:2 ){
for( j in 0:2 ) {
q = i + j*3 + 1
z = matrix(X[e.pick[q], ], nrow = 28, byrow=FALSE)
actual = trg[e.pick[q]]
pred = prd[e.pick[q]]
start.x = 2 + i * 34
start.y = 2 + j * 34
delta.x = start.x - 1
delta.y = start.y - 1
text(start.x-1,start.y-2, pos = 4,
sprintf('Actual: %d Predicted %d', actual, pred))
for( x in start.x:(start.x + 27) ){
for( y in start.y:(start.y + 27) ){
rect(x, y+1, x+1, y,
col = rgb(z[x-delta.x,y-delta.y],
z[x-delta.x,y-delta.y],
z[x-delta.x,y-delta.y], maxColorValue = 255),
border = NA)
}
}
}
}
}
plot.random.misclass(nn.trn,X.trn,Y.trn)
#get 9 random mistakes
prd = apply( X, 1, function(r) {
which.max(predict(nn.trn, matrix(r, nrow=1))) - 1
})
trg = apply(Y, 1, function(r) {
which.max(r) - 1
})
e = which(prd != trg)
e
length(e)
e.pick = sample(e, size = 9)
e.pick
plot(1:100,1:100, type='n', axes=FALSE, xlab='', ylab='', ylim=c(100,0) )
for( i in 0:2 ){
for( j in 0:2 ) {
q = i + j*3 + 1
z = matrix(X[e.pick[q], ], nrow = 28, byrow=FALSE)
actual = trg[e.pick[q]]
pred = prd[e.pick[q]]
start.x = 2 + i * 34
start.y = 2 + j * 34
delta.x = start.x - 1
delta.y = start.y - 1
text(start.x-1,start.y-2, pos = 4,
sprintf('Actual: %d Predicted %d', actual, pred))
for( x in start.x:(start.x + 27) ){
for( y in start.y:(start.y + 27) ){
rect(x, y+1, x+1, y,
col = rgb(z[x-delta.x,y-delta.y],
z[x-delta.x,y-delta.y],
z[x-delta.x,y-delta.y], maxColorValue = 255),
border = NA)
}
}
}
}
e.pick = sample(e, size = 9)
plot(1:100,1:100, type='n', axes=FALSE, xlab='', ylab='', ylim=c(100,0) )
for( i in 0:2 ){
for( j in 0:2 ) {
q = i + j*3 + 1
z = matrix(X[e.pick[q], ], nrow = 28, byrow=FALSE)
actual = trg[e.pick[q]]
pred = prd[e.pick[q]]
start.x = 2 + i * 34
start.y = 2 + j * 34
delta.x = start.x - 1
delta.y = start.y - 1
text(start.x-1,start.y-2, pos = 4,
sprintf('Actual: %d Predicted %d', actual, pred))
for( x in start.x:(start.x + 27) ){
for( y in start.y:(start.y + 27) ){
rect(x, y+1, x+1, y,
col = rgb(z[x-delta.x,y-delta.y],
z[x-delta.x,y-delta.y],
z[x-delta.x,y-delta.y], maxColorValue = 255),
border = NA)
}
}
}
}
#plot a random set of misclassified examples and show actual/predicted class
plot.random.misclass = function(nn.trn, X, Y) {
#get 9 random mistakes
prd = apply( X, 1, function(r) {
which.max(predict(nn.trn, matrix(r, nrow=1))) - 1
})
trg = apply(Y, 1, function(r) {
which.max(r) - 1
})
e = which(prd != trg)
e.pick = sample(e, size = 9)
plot(1:100,1:100, type='n', axes=FALSE, xlab='', ylab='', ylim=c(100,0) )
for( i in 0:2 ){
for( j in 0:2 ) {
q = i + j*3 + 1
z = matrix(X[e.pick[q], ], nrow = 28, byrow=FALSE)
actual = trg[e.pick[q]]
pred = prd[e.pick[q]]
start.x = 2 + i * 34
start.y = 2 + j * 34
delta.x = start.x - 1
delta.y = start.y - 1
text(start.x-1,start.y-2, pos = 4,
sprintf('Actual: %d Predicted %d', actual, pred))
for( x in start.x:(start.x + 27) ){
for( y in start.y:(start.y + 27) ){
rect(x, y+1, x+1, y,
col = rgb(z[x-delta.x,y-delta.y],
z[x-delta.x,y-delta.y],
z[x-delta.x,y-delta.y], maxColorValue = 255),
border = NA)
}
}
}
}
}
plot.random.misclass(nn.trn,X.trn,Y.trn)
#plot a random set of misclassified examples and show actual/predicted class
plot.random.misclass = function(nn.trn, X, Y) {
#get 9 random mistakes
prd = apply( X, 1, function(r) {
which.max(predict(nn.trn, matrix(r, nrow=1))) - 1
})
trg = apply(Y, 1, function(r) {
which.max(r) - 1
})
e = which(prd != trg)
print(length(e))
e.pick = sample(e, size = 9)
plot(1:100,1:100, type='n', axes=FALSE, xlab='', ylab='', ylim=c(100,0) )
for( i in 0:2 ){
for( j in 0:2 ) {
q = i + j*3 + 1
z = matrix(X[e.pick[q], ], nrow = 28, byrow=FALSE)
actual = trg[e.pick[q]]
pred = prd[e.pick[q]]
start.x = 2 + i * 34
start.y = 2 + j * 34
delta.x = start.x - 1
delta.y = start.y - 1
text(start.x-1,start.y-2, pos = 4,
sprintf('Actual: %d Predicted %d', actual, pred))
for( x in start.x:(start.x + 27) ){
for( y in start.y:(start.y + 27) ){
rect(x, y+1, x+1, y,
col = rgb(z[x-delta.x,y-delta.y],
z[x-delta.x,y-delta.y],
z[x-delta.x,y-delta.y], maxColorValue = 255),
border = NA)
}
}
}
}
}
plot.random.misclass(nn.trn,X.trn,Y.trn)
X = X.trn
Y = Y.trn
#get 9 random mistakes
prd = apply( X, 1, function(r) {
which.max(predict(nn.trn, matrix(r, nrow=1))) - 1
})
trg = apply(Y, 1, function(r) {
which.max(r) - 1
})
e = which(prd != trg)
e
#plot a random set of misclassified examples and show actual/predicted class
plot.random.misclass = function(nn.trn, X, Y) {
#get 9 random mistakes
prd = apply( X, 1, function(r) {
which.max(predict(nn.trn, matrix(r, nrow=1))) - 1
})
trg = apply(Y, 1, function(r) {
which.max(r) - 1
})
e = which(prd != trg)
print(length(e))
e.pick = sample(e, size = min(9,length(e)))
plot(1:100,1:100, type='n', axes=FALSE, xlab='', ylab='', ylim=c(100,0) )
for( i in 0:2 ){
for( j in 0:2 ) {
q = i + j*3 + 1
if( q <= length(e)) {
z = matrix(X[e.pick[q], ], nrow = 28, byrow=FALSE)
actual = trg[e.pick[q]]
pred = prd[e.pick[q]]
start.x = 2 + i * 34
start.y = 2 + j * 34
delta.x = start.x - 1
delta.y = start.y - 1
text(start.x-1,start.y-2, pos = 4,
sprintf('Actual: %d Predicted %d', actual, pred))
for( x in start.x:(start.x + 27) ){
for( y in start.y:(start.y + 27) ){
rect(x, y+1, x+1, y,
col = rgb(z[x-delta.x,y-delta.y],
z[x-delta.x,y-delta.y],
z[x-delta.x,y-delta.y], maxColorValue = 255),
border = NA)
}
}
}
}
}
}
plot.random.misclass(nn.trn,X.trn,Y.trn)
plot.random.misclass(nn.trn,X.val,Y.val)
plot.random.misclass(nn.trn,X.tst,Y.tst)
plot.random.misclass(nn.trn,X.tst,Y.tst)
#plot a random set of misclassified examples and show actual/predicted class
plot.random.misclass = function(nn.trn, X, Y) {
#get 9 random mistakes
prd = apply( X, 1, function(r) {
which.max(predict(nn.trn, matrix(r, nrow=1))) - 1
})
trg = apply(Y, 1, function(r) {
which.max(r) - 1
})
e = which(prd != trg)
e.pick = sample(e, size = min(9,length(e)))
plot(1:100,1:100, type='n', axes=FALSE, xlab='', ylab='', ylim=c(100,0) )
for( i in 0:2 ){
for( j in 0:2 ) {
q = i + j*3 + 1
if( q <= length(e)) {
z = matrix(X[e.pick[q], ], nrow = 28, byrow=FALSE)
actual = trg[e.pick[q]]
pred = prd[e.pick[q]]
start.x = 2 + i * 34
start.y = 2 + j * 34
delta.x = start.x - 1
delta.y = start.y - 1
text(start.x-1,start.y-2, pos = 4,
sprintf('Actual: %d Predicted %d', actual, pred))
for( x in start.x:(start.x + 27) ){
for( y in start.y:(start.y + 27) ){
rect(x, y+1, x+1, y,
col = rgb(z[x-delta.x,y-delta.y],
z[x-delta.x,y-delta.y],
z[x-delta.x,y-delta.y], maxColorValue = 255),
border = NA)
}
}
}
}
}
}
plot.random.misclass(nn.trn,X.tst,Y.tst)
source('/storage/ColoComp/Development/NNFS/NNFS.R')
# get accuracy function for later use
get.acc = function(nn, X.trn, target, show.conf.mat = FALSE) {
prd = apply( X.trn, 1, function(r) {
which.max(predict(nn, matrix(r, nrow=1))) - 1
})
t = table(target, prd)
if( show.conf.mat ){
print(t)
}
sum(diag(t))/sum(t)
}
#plot a random set of misclassified examples and show actual/predicted class
plot.random.misclass = function(nn.trn, X, Y) {
#get 9 random mistakes
prd = apply( X, 1, function(r) {
which.max(predict(nn.trn, matrix(r, nrow=1))) - 1
})
trg = apply(Y, 1, function(r) {
which.max(r) - 1
})
e = which(prd != trg)
e.pick = sample(e, size = min(9,length(e)))
plot(1:100,1:100, type='n', axes=FALSE, xlab='', ylab='', ylim=c(100,0) )
for( i in 0:2 ){
for( j in 0:2 ) {
q = i + j*3 + 1
if( q <= length(e)) {
z = matrix(X[e.pick[q], ], nrow = 28, byrow=FALSE)
actual = trg[e.pick[q]]
pred = prd[e.pick[q]]
start.x = 2 + i * 34
start.y = 2 + j * 34
delta.x = start.x - 1
delta.y = start.y - 1
text(start.x-1,start.y-2, pos = 4,
sprintf('Actual: %d Predicted %d', actual, pred))
for( x in start.x:(start.x + 27) ){
for( y in start.y:(start.y + 27) ){
rect(x, y+1, x+1, y,
col = rgb(z[x-delta.x,y-delta.y],
z[x-delta.x,y-delta.y],
z[x-delta.x,y-delta.y], maxColorValue = 255),
border = NA)
}
}
}
}
}
}
# get orginal data
d.pixels = read.csv('../MNIST_dataset/mnist_pixels.csv', header = TRUE)
d.onehot.labels = read.csv('../MNIST_dataset/mnist_labels_onehot.csv', header = TRUE)
# build training, validation, test sets
set.seed(181117)
indices = sample(1:42000, 42000, replace = FALSE)
train.set = indices[1:21000]
val.set = indices[21001:31500]
test.set = indices[31501:42000]
# reduced set sizes for experiments and tuning
train.set = indices[1:2100]
val.set = indices[2101:3150]
test.set = indices[3151:4200]
X.trn = as.matrix(d.pixels[train.set, ])
Y.trn = as.matrix(d.onehot.labels[train.set, ])
digit.trn = apply(Y.trn, 1, function(r) {
which.max(r) - 1
})
X.val = as.matrix(d.pixels[val.set, ])
Y.val = as.matrix(d.onehot.labels[val.set, ])
digit.val = apply(Y.val, 1, function(r) {
which.max(r) -1
})
X.tst = as.matrix(d.pixels[test.set, ])
Y.tst = as.matrix(d.onehot.labels[test.set, ])
digit.tst = apply(Y.tst, 1, function(r) {
which.max(r) - 1
})
# 2-layer
nn.trn = NNModel(input.dim = 784, layers=c(15, 10), activation=c('sigmoid', 'softmax'))
learning.rate = 0.1
n.epochs = 250
#look at the confusion matrices before training
get.acc(nn.trn, X.trn, digit.trn, show.conf.mat = TRUE)
get.acc(nn.trn, X.val, digit.val, show.conf.mat = TRUE)
get.acc(nn.trn, X.tst, digit.tst, show.conf.mat = TRUE)
for( e in 1:n.epochs) {
nn.trn = train(nn.trn,X.trn,Y.trn, epochs=1, mini.batch.size=100, learning.rate=learning.rate)
points( rep(e,3), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
}
# multiple epochs with plotting between epochs
# set up accuracy plotting
plot( 0:n.epochs, seq(0,1,length.out=(n.epochs+1)), type = 'n',
xlab = 'Epoch #', ylab = 'Accuracy')
grid()
points( c(0,0,0), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
legend('bottomright', legend=c('Training', 'Validation', 'Test'),
pt.bg = c('blue', 'darkorange', 'red'), pch=21, col = 'black')
#look at the confusion matrices before training
get.acc(nn.trn, X.trn, digit.trn, show.conf.mat = TRUE)
get.acc(nn.trn, X.val, digit.val, show.conf.mat = TRUE)
get.acc(nn.trn, X.tst, digit.tst, show.conf.mat = TRUE)
for( e in 1:n.epochs) {
nn.trn = train(nn.trn,X.trn,Y.trn, epochs=1, mini.batch.size=100, learning.rate=learning.rate)
points( rep(e,3), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
}
#look at the confusion matrices before training
get.acc(nn.trn, X.trn, digit.trn, show.conf.mat = TRUE)
get.acc(nn.trn, X.val, digit.val, show.conf.mat = TRUE)
get.acc(nn.trn, X.tst, digit.tst, show.conf.mat = TRUE)
plot.random.misclass(nn.trn,X.trn,Y.trn)
plot.random.misclass(nn.trn,X.val,Y.val)
plot.random.misclass(nn.trn,X.tst,Y.tst)
# build training, validation, test sets
set.seed(181117)
indices = sample(1:42000, 42000, replace = FALSE)
train.set = indices[1:21000]
val.set = indices[21001:31500]
test.set = indices[31501:42000]
X.trn = as.matrix(d.pixels[train.set, ])
Y.trn = as.matrix(d.onehot.labels[train.set, ])
digit.trn = apply(Y.trn, 1, function(r) {
which.max(r) - 1
})
X.val = as.matrix(d.pixels[val.set, ])
Y.val = as.matrix(d.onehot.labels[val.set, ])
digit.val = apply(Y.val, 1, function(r) {
which.max(r) -1
})
X.tst = as.matrix(d.pixels[test.set, ])
Y.tst = as.matrix(d.onehot.labels[test.set, ])
digit.tst = apply(Y.tst, 1, function(r) {
which.max(r) - 1
})
# 2-layer
nn.trn = NNModel(input.dim = 784, layers=c(15, 10), activation=c('sigmoid', 'softmax'))
learning.rate = 0.1
n.epochs = 250
# multiple epochs with plotting between epochs
# set up accuracy plotting
plot( 0:n.epochs, seq(0,1,length.out=(n.epochs+1)), type = 'n',
xlab = 'Epoch #', ylab = 'Accuracy')
grid()
points( c(0,0,0), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
legend('bottomright', legend=c('Training', 'Validation', 'Test'),
pt.bg = c('blue', 'darkorange', 'red'), pch=21, col = 'black')
#look at the confusion matrices before training
get.acc(nn.trn, X.trn, digit.trn, show.conf.mat = TRUE)
get.acc(nn.trn, X.val, digit.val, show.conf.mat = TRUE)
get.acc(nn.trn, X.tst, digit.tst, show.conf.mat = TRUE)
for( e in 1:n.epochs) {
nn.trn = train(nn.trn,X.trn,Y.trn, epochs=1, mini.batch.size=100, learning.rate=learning.rate)
points( rep(e,3), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
}
#confusion matrices after training
get.acc(nn.trn, X.trn, digit.trn, show.conf.mat = TRUE)
get.acc(nn.trn, X.val, digit.val, show.conf.mat = TRUE)
get.acc(nn.trn, X.tst, digit.tst, show.conf.mat = TRUE)
plot.random.misclass(nn.trn,X.trn,Y.trn)
plot.random.misclass(nn.trn,X.val,Y.val)
plot.random.misclass(nn.trn,X.tst,Y.tst)
# 3-layer
nn.trn = NNModel(input.dim = 784, layers=c(20, 20, 10),
activation=c('sigmoid', 'sigmoid', 'softmax'))
learning.rate = 0.1
n.epochs = 1000
for( e in 1:n.epochs) {
nn.trn = train(nn.trn,X.trn,Y.trn, epochs=1, mini.batch.size=100, learning.rate=learning.rate)
points( rep(e,3), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
}
# multiple epochs with plotting between epochs
# set up accuracy plotting
plot( 0:n.epochs, seq(0,1,length.out=(n.epochs+1)), type = 'n',
xlab = 'Epoch #', ylab = 'Accuracy')
grid()
points( c(0,0,0), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
legend('bottomright', legend=c('Training', 'Validation', 'Test'),
pt.bg = c('blue', 'darkorange', 'red'), pch=21, col = 'black')
#look at the confusion matrices before training
get.acc(nn.trn, X.trn, digit.trn, show.conf.mat = TRUE)
get.acc(nn.trn, X.val, digit.val, show.conf.mat = TRUE)
get.acc(nn.trn, X.tst, digit.tst, show.conf.mat = TRUE)
for( e in 1:n.epochs) {
nn.trn = train(nn.trn,X.trn,Y.trn, epochs=1, mini.batch.size=100, learning.rate=learning.rate)
points( rep(e,3), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
}
#confusion matrices after training
get.acc(nn.trn, X.trn, digit.trn, show.conf.mat = TRUE)
get.acc(nn.trn, X.val, digit.val, show.conf.mat = TRUE)
get.acc(nn.trn, X.tst, digit.tst, show.conf.mat = TRUE)
plot.random.misclass(nn.trn,X.trn,Y.trn)
plot.random.misclass(nn.trn,X.val,Y.val)
plot.random.misclass(nn.trn,X.tst,Y.tst)
plot.random.misclass(nn.trn,X.trn,Y.trn)
# 5-layer
nn.trn = NNModel(input.dim = 784, layers=c(25, 20, 15, 10, 10),
activation=c('leaky.relu', 'leaky.relu', 'leaky.relu', 'leaky.relu', 'softmax'))
learning.rate = 0.01
n.epochs = 2500
n.epochs = 5000
# multiple epochs with plotting between epochs
# set up accuracy plotting
plot( 0:n.epochs, seq(0,1,length.out=(n.epochs+1)), type = 'n',
xlab = 'Epoch #', ylab = 'Accuracy')
grid()
points( c(0,0,0), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
legend('bottomright', legend=c('Training', 'Validation', 'Test'),
pt.bg = c('blue', 'darkorange', 'red'), pch=21, col = 'black')
#look at the confusion matrices before training
get.acc(nn.trn, X.trn, digit.trn, show.conf.mat = TRUE)
get.acc(nn.trn, X.val, digit.val, show.conf.mat = TRUE)
get.acc(nn.trn, X.tst, digit.tst, show.conf.mat = TRUE)
for( e in 1:n.epochs) {
nn.trn = train(nn.trn,X.trn,Y.trn, epochs=1, mini.batch.size=100, learning.rate=learning.rate)
points( rep(e,3), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
}
#confusion matrices after training
get.acc(nn.trn, X.trn, digit.trn, show.conf.mat = TRUE)
get.acc(nn.trn, X.val, digit.val, show.conf.mat = TRUE)
get.acc(nn.trn, X.tst, digit.tst, show.conf.mat = TRUE)
plot.random.misclass(nn.trn,X.val,Y.val)
plot.random.misclass(nn.trn,X.tst,Y.tst)
