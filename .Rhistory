#compute marginal probabilities
n <- sum(d)
pi.iplus.vect <- rowSums(d)/n
pi.plusj.vect <- colSums(d)/n
#compute expectd values
e <- data.frame( matrix( c(pi.plus.vect[1] * pi.plusj.vect[1] * n,
pi.plus.vect[1] * pi.plusj.vect[2] * n,
pi.plus.vect[2] * pi.plusj.vect[1] * n,
pi.plus.vect[2] * pi.plusj.vect[2] * n),
byrow = TRUE))
#compute expectd values
e <- data.frame( matrix( c(pi.iplus.vect[1] * pi.plusj.vect[1] * n,
pi.iplus.vect[1] * pi.plusj.vect[2] * n,
pi.iplus.vect[2] * pi.plusj.vect[1] * n,
pi.iplus.vect[2] * pi.plusj.vect[2] * n),
byrow = TRUE))
e
colnames(e) <- colnames(d)
rownames(e) <- rownames(d)
#compute expectd values
e <- data.frame( matrix( c(pi.iplus.vect[1] * pi.plusj.vect[1] * n,
pi.iplus.vect[1] * pi.plusj.vect[2] * n,
pi.iplus.vect[2] * pi.plusj.vect[1] * n,
pi.iplus.vect[2] * pi.plusj.vect[2] * n),
byrow = TRUE, nrow =2 ))
colnames(e) <- colnames(d)
rownames(e) <- rownames(d)
e
round(e, 2)
d
e
(d-e)^2/e
chi.sq.stat = sum( (d - e) / e )
p.val = pchisq(chi.sq.stat, df = 1, lower.tail = 1)
print(sprintf('The p-value for the test is:  %0.3f', p.val))
chi.sq.stat = sum( (d - e)^2 / e )
p.val = pchisq(chi.sq.stat, df = 1, lower.tail = 1)
print(sprintf('The p-value for the test is:  %0.3f', p.val))
chisq.test(d)
chisq.test(d, correct = FALSE)
p.val = pchisq(chi.sq.stat, df = 1, lower.tail = FALSE)
print(sprintf('The p-value for the test is:  %0.3f', p.val))
chisq.test(d, correct = FALSE)
outline1 = sprintf('The chi-squared statistic is:  %0.3f', chi.sq.stat)
outline2 = sprintf('The p-value for the test is:  %0.3f', p.val)
cat(sprintf('%s\n%s', outline1, outline2))
outline1 = sprintf('The chi-squared statistic is:  %0.3e', chi.sq.stat)
outline2 = sprintf('The p-value for the test is:  %0.3f', p.val)
cat(sprintf('%s\n%s', outline1, outline2))
p1 = rep('.', 23)
p2 = rep('*', 23)
p1
p2
runif()
runif(1,0,1)
runif(1,0,1)
runif(1,0,1)
runif(1,0,1)
hist(runif(500,0,1))
mean(runif(500,0,1))
mean(runif(5000,0,1))
hist(runif(5000,0,1))
p1 = rep('.', 23)
p2 = rep('*', 23)
me = sapply(1:23, function(i) {
if( runif(1,0,1) >= 0.5) {
p1[i]
} else {
p2[i]
}
})
me
length(which(me) == '*')
length(which(me == '*'))
me = sapply(1:23, function(i) {
if( runif(1,0,1) >= 0.5) {
p1[i]
} else {
p2[i]
}
})
length(which(me == '*'))
c = sapply(1:23, function(i) {
if( runif(1,0,1) >= 0.5) {
p1[i]
} else {
c[i]
}
})
p1 = rep('.', 23)
p2 = rep('*', 23)
n = 100
mix = function(p1, p2) {
sapply(1:23, function(i) {
if( runif(1,0,1) >= 0.5) {
p1[i]
} else {
p2[i]
}
})
}
c1 = mix(p1, p2)
c2 = mix(p1, c1)
c3 = mix(p1, c2)
c3
length(which(c3 == '*'))
p1 = rep('.', 23)
p2 = rep('*', 23)
n = 100
mix = function(p1, p2) {
sapply(1:23, function(i) {
if( runif(1,0,1) >= 0.5) {
p1[i]
} else {
p2[i]
}
})
}
sapply(1:n, function(i) {
c1 = mix(p1, p2)
c2 = mix(p1, c1)
c3 = mix(p1, c2)
length(which(c3 == '*'))
})
sim = sapply(1:n, function(i) {
c1 = mix(p1, p2)
c2 = mix(p1, c1)
c3 = mix(p1, c2)
length(which(c3 == '*'))
})
length( which(sim == 0) )/n
n = 1000
p1 = rep('.', 23)
p2 = rep('*', 23)
mix = function(p1, p2) {
sapply(1:23, function(i) {
if( runif(1,0,1) >= 0.5) {
p1[i]
} else {
p2[i]
}
})
}
gen.test = function(n) {
n = 1000
sim = sapply(1:n, function(i) {
c1 = mix(p1, p2)
c2 = mix(p1, c1)
c3 = mix(p1, c2)
length(which(c3 == '*'))
})
length( which(sim == 0) )/n
}
gen.test(100)
gen.test(100)
gen.test(100)
gen.test(100)
gen.test(1000)
gen.test(1000)
gen.test(1000)
gen.test(1000)
gen.test(1000)
gen.test(1000)
gen.test(1000)
gen.test(1000000)
gen.test(1000000)
gen.test(1000000)
gen.test(1000000)
gen.test(1000000)
gen.test(1000000)
gen.test(1000000)
gen.test(1000000)
gen.test(10000000)
gen.test(10000000)
gen.test(10000000)
gen.test(10000000)
gen.test(10000000)
res = rmultinom(100,23,prob=c(.125,.875))
res
length(which(res[1,] == 0))
n=10000000
res = rmultinom(n,23,prob=c(.125,.875))
length(which(res[1,] == 0))/n
pbinom(0, 23, prob = .125, lower.tail = FALSE)
pbinom(0, 23, prob = .125)
install.packages(c("coda", "devtools", "digest", "dplyr", "epiR", "evaluate", "fansi", "ggplot2", "mime", "R6", "Rcpp", "rlang", "rstudioapi", "servr", "shiny", "tidyselect", "tinytex", "xfun"))
version()
Version()
R.Version()
R.Version()
R.version
install.package('glmnet')
install.packages('glmnet')
library(datamicroarray)
data('alon', package = 'datamicroarray')
x = as.matrix(alon$x)
y = as.matrix(alon$y)
dim(x)
dim(y)
y
y = as.factor(y)
y
glmmod = glmnet(x, y, alpha=1, family='binomial')
library(glmnet)
glmmod = glmnet(x, y, alpha=1, family='binomial')
glmmod
plot(glmmod)
plot(glmmod, xvar='lambda')
cv.glmmod = cv.glmnet(x,y,alpha=1)
cv.glmmod = cv.glmnet(x,y=as.numeric(y),alpha=1)
cv.glmmod
plot(cv.glmmod)
best.lambda = cv.glmmod$lambda.min
glmmod = glmnet(x, y, alpha=1, family='binomial', lambda = best.lambda)
coeff(glmmod)
coefficients(glmmod)
i = which(coefficients(glmmod) != 0)
i
x.red = x[,i]
dimx.red
dim(x.red)
glm.coeffs = coefficients(glmmod)[i]
glm.coeffs
glmmod.red = glmnet(x.red,y,family='binomial',alpha=1 )
coefficients(glmmod.red)
glm.red = glm(y~x.red, family='binomial')
coeff(glm.red)
coefficients(glm.red)
glm.coeffs
source('/storage/ColoComp/Development/NNFS/NNFS.R')
# get accuracy function for later use
get.acc = function(nn, X.trn, target, show.conf.mat = FALSE) {
prd = apply( X.trn, 1, function(r) {
which.max(predict(nn, matrix(r, nrow=1))) - 1
})
t = table(target, prd)
if( show.conf.mat ){
print(t)
}
sum(diag(t))/sum(t)
}
# get orginal data
d.pixels = read.csv('../MNIST_dataset/mnist_pixels.csv', header = TRUE)
setwd("/storage/ColoComp/Development/NNFS")
# get orginal data
d.pixels = read.csv('../MNIST_dataset/mnist_pixels.csv', header = TRUE)
d.onehot.labels = read.csv('../MNIST_dataset/mnist_labels_onehot.csv', header = TRUE)
# build training, validation, test sets
set.seed(181110)
indices = sample(1:42000, 42000, replace = FALSE)
train.set = indices[1:21000]
val.set = indices[21001:31500]
test.set = indices[31501:42000]
# reduced set sizes for experiments and tuning
train.set = indices[1:2100]
val.set = indices[2101:3150]
test.set = indices[3151:4200]
X.trn = as.matrix(d.pixels[train.set, ])
Y.trn = as.matrix(d.onehot.labels[train.set, ])
digit.trn = apply(Y.trn, 1, function(r) {
which.max(r) - 1
})
X.val = as.matrix(d.pixels[val.set, ])
Y.val = as.matrix(d.onehot.labels[val.set, ])
digit.val = apply(Y.val, 1, function(r) {
which.max(r) -1
})
X.tst = as.matrix(d.pixels[test.set, ])
Y.tst = as.matrix(d.onehot.labels[test.set, ])
digit.tst = apply(Y.tst, 1, function(r) {
which.max(r) - 1
})
# 2-layer
nn.trn = NNModel(input.dim = 784, layers=c(15, 10), activation=c('sigmoid', 'softmax'))
# 5-layer
nn.trn = NNModel(input.dim = 784, layers=c(15, 10, 10, 5, 10),
activation=c('leaky.relu', 'leaky.relu', 'leaky.relu', 'leaky.relu', 'softmax'))
learning.rate = 0.001
n.epochs = 1000
# multiple epochs with plotting between epochs
# set up accuracy plotting
plot( 0:n.epochs, seq(0,1,length.out=(n.epochs+1)), type = 'n',
xlab = 'Epoch #', ylab = 'Accuracy')
grid()
points( c(0,0,0), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
legend('bottomright', legend=c('Training', 'Validation', 'Test'),
pt.bg = c('blue', 'darkorange', 'red'), pch=21, col = 'black')
#look at the confusion matrices before training
get.acc(nn.trn, X.trn, digit.trn, show.conf.mat = TRUE)
get.acc(nn.trn, X.val, digit.val, show.conf.mat = TRUE)
get.acc(nn.trn, X.tst, digit.tst, show.conf.mat = TRUE)
for( e in 1:n.epochs) {
nn.trn = train(nn.trn,X.trn,Y.trn, epochs=1, mini.batch.size=100, learning.rate=learning.rate)
points( rep(e,3), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
}
learning.rate = 0.01
n.epochs = 1000
# multiple epochs with plotting between epochs
# set up accuracy plotting
plot( 0:n.epochs, seq(0,1,length.out=(n.epochs+1)), type = 'n',
xlab = 'Epoch #', ylab = 'Accuracy')
grid()
points( c(0,0,0), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
legend('bottomright', legend=c('Training', 'Validation', 'Test'),
pt.bg = c('blue', 'darkorange', 'red'), pch=21, col = 'black')
#look at the confusion matrices before training
get.acc(nn.trn, X.trn, digit.trn, show.conf.mat = TRUE)
get.acc(nn.trn, X.val, digit.val, show.conf.mat = TRUE)
get.acc(nn.trn, X.tst, digit.tst, show.conf.mat = TRUE)
for( e in 1:n.epochs) {
nn.trn = train(nn.trn,X.trn,Y.trn, epochs=1, mini.batch.size=100, learning.rate=learning.rate)
points( rep(e,3), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
}
# 5-layer
nn.trn = NNModel(input.dim = 784, layers=c(10, 10, 5, 5, 10),
activation=c('leaky.relu', 'leaky.relu', 'leaky.relu', 'leaky.relu', 'softmax'))
learning.rate = 0.01
n.epochs = 1000
# multiple epochs with plotting between epochs
# set up accuracy plotting
plot( 0:n.epochs, seq(0,1,length.out=(n.epochs+1)), type = 'n',
xlab = 'Epoch #', ylab = 'Accuracy')
grid()
points( c(0,0,0), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
legend('bottomright', legend=c('Training', 'Validation', 'Test'),
pt.bg = c('blue', 'darkorange', 'red'), pch=21, col = 'black')
#look at the confusion matrices before training
get.acc(nn.trn, X.trn, digit.trn, show.conf.mat = TRUE)
get.acc(nn.trn, X.val, digit.val, show.conf.mat = TRUE)
get.acc(nn.trn, X.tst, digit.tst, show.conf.mat = TRUE)
for( e in 1:n.epochs) {
nn.trn = train(nn.trn,X.trn,Y.trn, epochs=1, mini.batch.size=100, learning.rate=learning.rate)
points( rep(e,3), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
}
# 5-layer
nn.trn = NNModel(input.dim = 784, layers=c(5, 5, 5, 5, 10),
activation=c('leaky.relu', 'leaky.relu', 'leaky.relu', 'leaky.relu', 'softmax'))
learning.rate = 0.01
n.epochs = 1000
# multiple epochs with plotting between epochs
# set up accuracy plotting
plot( 0:n.epochs, seq(0,1,length.out=(n.epochs+1)), type = 'n',
xlab = 'Epoch #', ylab = 'Accuracy')
grid()
points( c(0,0,0), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
legend('bottomright', legend=c('Training', 'Validation', 'Test'),
pt.bg = c('blue', 'darkorange', 'red'), pch=21, col = 'black')
#look at the confusion matrices before training
get.acc(nn.trn, X.trn, digit.trn, show.conf.mat = TRUE)
get.acc(nn.trn, X.val, digit.val, show.conf.mat = TRUE)
get.acc(nn.trn, X.tst, digit.tst, show.conf.mat = TRUE)
for( e in 1:n.epochs) {
nn.trn = train(nn.trn,X.trn,Y.trn, epochs=1, mini.batch.size=100, learning.rate=learning.rate)
points( rep(e,3), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
}
# 5-layer
nn.trn = NNModel(input.dim = 784, layers=c(5, 5, 5, 5, 10),
activation=c('leaky.relu', 'leaky.relu', 'leaky.relu', 'leaky.relu', 'softmax'))
learning.rate = 0.1
n.epochs = 1000
# multiple epochs with plotting between epochs
# set up accuracy plotting
plot( 0:n.epochs, seq(0,1,length.out=(n.epochs+1)), type = 'n',
xlab = 'Epoch #', ylab = 'Accuracy')
grid()
points( c(0,0,0), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
legend('bottomright', legend=c('Training', 'Validation', 'Test'),
pt.bg = c('blue', 'darkorange', 'red'), pch=21, col = 'black')
#look at the confusion matrices before training
get.acc(nn.trn, X.trn, digit.trn, show.conf.mat = TRUE)
get.acc(nn.trn, X.val, digit.val, show.conf.mat = TRUE)
get.acc(nn.trn, X.tst, digit.tst, show.conf.mat = TRUE)
for( e in 1:n.epochs) {
nn.trn = train(nn.trn,X.trn,Y.trn, epochs=1, mini.batch.size=100, learning.rate=learning.rate)
points( rep(e,3), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
}
# 5-layer
nn.trn = NNModel(input.dim = 784, layers=c(5, 5, 5, 5, 10),
activation=c('leaky.relu', 'leaky.relu', 'leaky.relu', 'leaky.relu', 'softmax'))
learning.rate = 0.05
n.epochs = 1000
# multiple epochs with plotting between epochs
# set up accuracy plotting
plot( 0:n.epochs, seq(0,1,length.out=(n.epochs+1)), type = 'n',
xlab = 'Epoch #', ylab = 'Accuracy')
grid()
points( c(0,0,0), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
legend('bottomright', legend=c('Training', 'Validation', 'Test'),
pt.bg = c('blue', 'darkorange', 'red'), pch=21, col = 'black')
#look at the confusion matrices before training
get.acc(nn.trn, X.trn, digit.trn, show.conf.mat = TRUE)
get.acc(nn.trn, X.val, digit.val, show.conf.mat = TRUE)
get.acc(nn.trn, X.tst, digit.tst, show.conf.mat = TRUE)
for( e in 1:n.epochs) {
nn.trn = train(nn.trn,X.trn,Y.trn, epochs=1, mini.batch.size=100, learning.rate=learning.rate)
points( rep(e,3), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
}
# 5-layer
nn.trn = NNModel(input.dim = 784, layers=c(5, 5, 5, 5, 10),
activation=c('leaky.relu', 'leaky.relu', 'leaky.relu', 'leaky.relu', 'softmax'))
learning.rate = 0.01
n.epochs = 1000
# multiple epochs with plotting between epochs
# set up accuracy plotting
plot( 0:n.epochs, seq(0,1,length.out=(n.epochs+1)), type = 'n',
xlab = 'Epoch #', ylab = 'Accuracy')
grid()
points( c(0,0,0), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
legend('bottomright', legend=c('Training', 'Validation', 'Test'),
pt.bg = c('blue', 'darkorange', 'red'), pch=21, col = 'black')
#look at the confusion matrices before training
get.acc(nn.trn, X.trn, digit.trn, show.conf.mat = TRUE)
get.acc(nn.trn, X.val, digit.val, show.conf.mat = TRUE)
get.acc(nn.trn, X.tst, digit.tst, show.conf.mat = TRUE)
for( e in 1:n.epochs) {
nn.trn = train(nn.trn,X.trn,Y.trn, epochs=1, mini.batch.size=100, learning.rate=learning.rate)
points( rep(e,3), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
}
# build training, validation, test sets
set.seed(181110)
indices = sample(1:42000, 42000, replace = FALSE)
train.set = indices[1:21000]
val.set = indices[21001:31500]
test.set = indices[31501:42000]
X.trn = as.matrix(d.pixels[train.set, ])
Y.trn = as.matrix(d.onehot.labels[train.set, ])
digit.trn = apply(Y.trn, 1, function(r) {
which.max(r) - 1
})
X.val = as.matrix(d.pixels[val.set, ])
Y.val = as.matrix(d.onehot.labels[val.set, ])
digit.val = apply(Y.val, 1, function(r) {
which.max(r) -1
})
X.tst = as.matrix(d.pixels[test.set, ])
Y.tst = as.matrix(d.onehot.labels[test.set, ])
digit.tst = apply(Y.tst, 1, function(r) {
which.max(r) - 1
})
# 5-layer
nn.trn = NNModel(input.dim = 784, layers=c(5, 5, 5, 5, 10),
activation=c('leaky.relu', 'leaky.relu', 'leaky.relu', 'leaky.relu', 'softmax'))
learning.rate = 0.01
n.epochs = 1000
# multiple epochs with plotting between epochs
# set up accuracy plotting
plot( 0:n.epochs, seq(0,1,length.out=(n.epochs+1)), type = 'n',
xlab = 'Epoch #', ylab = 'Accuracy')
grid()
points( c(0,0,0), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
legend('bottomright', legend=c('Training', 'Validation', 'Test'),
pt.bg = c('blue', 'darkorange', 'red'), pch=21, col = 'black')
#look at the confusion matrices before training
get.acc(nn.trn, X.trn, digit.trn, show.conf.mat = TRUE)
get.acc(nn.trn, X.val, digit.val, show.conf.mat = TRUE)
get.acc(nn.trn, X.tst, digit.tst, show.conf.mat = TRUE)
for( e in 1:n.epochs) {
nn.trn = train(nn.trn,X.trn,Y.trn, epochs=1, mini.batch.size=100, learning.rate=learning.rate)
points( rep(e,3), c(get.acc(nn.trn, X.trn, digit.trn),
get.acc(nn.trn, X.val, digit.val),
get.acc(nn.trn, X.tst, digit.tst)),
bg = c('blue', 'darkorange', 'red'), pch = 21, col='black')
}
#confusion matrices after training
get.acc(nn.trn, X.trn, digit.trn, show.conf.mat = TRUE)
get.acc(nn.trn, X.val, digit.val, show.conf.mat = TRUE)
get.acc(nn.trn, X.tst, digit.tst, show.conf.mat = TRUE)
