rho1 <- 18 / 79
rho2 <- 14 / 79
RR.hat <- rho1/rho2
print(sprintf(
'Relative risk of older patient death versus younger patient death:  %0.3f',
RR.hat))
log.RR.hat <- log(RR.hat)
var.log.RR.hat <- (1 - rho1)/(rho1 * 79) + (1 - rho2)/(rho2 * 79)
upper.lim = log.RR.hat + 1.96 * sqrt(var.log.RR.hat)
lower.lim = log.RR.hat - 1.96 * sqrt(var.log.RR.hat)
print(sprintf('The confidence interval is:  (%0.3f, %0.3f)',
exp(lower.lim), exp(upper.lim)))
var.dop = (rho1 * (1 - rho1))/(16 + 2045) + (rho2 + (1 - rho2))/(7 + 1044)
dop = rho1 - rho2
var.dop = (rho1 * (1 - rho1))/(16 + 2045) + (rho2 + (1 - rho2))/(7 + 1044)
upper.lim = dop + 1.96 * sqrt(var.dop)
lower.lim = dop - 1.96 * sqrt(var.dop)
print(sprintf('The confidence interval is:  (%0.3f, %0.3f)',
lower.lim, upper.lim))
rho1 = 16 / (16 + 2045)
rho2 = 7 / (7 + 1044)
RR.hat <- rho1/rho2
print(sprintf(
'Relative risk of obese person death versue non-obese person death:  %0.3f',
RR.hat))
log.RR.hat <- log(RR.hat)
var.log.RR.hat <- (1 - rho1)/(rho1 * (16 + 2045)) + (1 - rho2)/(rho2 * (7 + 1044))
upper.lim = log.RR.hat + 1.96 * sqrt(var.log.RR.hat)
lower.lim = log.RR.hat - 1.96 * sqrt(var.log.RR.hat)
print(sprintf('The confidence interval is:  (%0.3f, %0.3f)',
exp(lower.lim), exp(upper.lim)))
1/samoa
sum(1/samoa)
samoa
1/16 + 1/2045 + 1/7 + 1/1044
log.OR.hat <- log(OR.hat)
var.log.OR.hat <- sum(1/samoa)
upper.lim <- log.OR.hat + 1.96 * sqrt(var.log.OR.hat)
lower.lim <- log.OR.hat - 1.96 * sqrt(var.log.OR.hat)
OR.hat <- (rho1 / (1 - rho1))/(rho2 / (1 - rho2))
print(sprintf('The odds ratio of CVD Death in obese vs. non-obese individuals is %0.3f',
OR.hat))
RR.hat
log.OR.hat <- log(OR.hat)
var.log.OR.hat <- sum(1/samoa)
upper.lim <- log.OR.hat + 1.96 * sqrt(var.log.OR.hat)
lower.lim <- log.OR.hat - 1.96 * sqrt(var.log.OR.hat)
print(sprintf('The confidence interval is:  (%0.3f, %0.3f)',
exp(lower.lim), exp(upper.lim)))
OR.from.RR = RR.hat * (1-rho2)/1-(rho1)
OR.hat
OR.from.RR
samoa
OR.from.RR = RR.hat * (1 - rho2)/(1 - rho1)
print(sprintf('Actual Odds Ratio = %0.3f', OR.hat))
print(sprintf('Odds Ratio from Relative Risk = %0.3f', OR.from.RR))
library(epiR)
install.packages('epiR')
library(epiR)
res = epi.2by2(x)
res = epi.2by2(samoa)
res
?epi.2by2
res$tab
res$res$RR.crude.score
res$res$
res$res
#RR and Wald CI
res$res$RR.mh.wald
res$res$RR.conf
##OR and Wald CI
res$res$OR.mh.wald
res$res$OR.crude.wald
res$res$RR.crude.wald
rmultinom(1,23,prob=.125)
rmultinom(1,23,prob=.125)
?rmultinom
rmultinom(23,1,prob=.125)
rmultinom(23,1,prob=c(.125,.875))
rmultinom(1,23,prob=c(.125,.875))
rmultinom(1,23,prob=c(.125,.875))
3/23
rmultinom(10,23,prob=c(.125,.875))
rmultinom(100,23,prob=c(.125,.875))
res = rmultinom(100,23,prob=c(.125,.875))
res
length(which(res[1,] = 0))
length(which(res[1,] == 0))
res = rmultinom(100,23,prob=c(.125,.875))
length(which(res[1,] == 0))
n=1000
res = rmultinom(n,23,prob=c(.125,.875))
length(which(res[1,] == 0))/n
n=1000
res = rmultinom(n,23,prob=c(.125,.875))
length(which(res[1,] == 0))/n
n=1000000
res = rmultinom(n,23,prob=c(.125,.875))
length(which(res[1,] == 0))/n
n=1000000
res = rmultinom(n,23,prob=c(.125,.875))
length(which(res[1,] == 0))/n
n=10000000
res = rmultinom(n,23,prob=c(.125,.875))
length(which(res[1,] == 0))/n
d <- data.frame( Try2.Miss = c(8, 33), Try2.Make = c(37, 152) )
rownames(d) = c('Try1.Miss', 'Try1.Make')
d
epi.2by2(d)
d
epi.2by2(d)
samoa
epi.2by2(samoa)
samoa
chisq.test(d)
chisq.test(d, simulate.p.value = TRUE)
n <- sum(d)
pi.iplus.vect = rowSums(d)/n
pi.plusj.vect = colsums(d)/n
pi.plusj.vect = colSums(d)/n
d
sum(d)
8_37
8+37
45/230
185/230
#compute expectd values
e <- data.frame( matrix( c(pi.plus.vect[1] * pi.plusj.vect[1] * n,
pi.plus.vect[1] * pi.plusj.vect[2] * n,
pi.plus.vect[2] * pi.plusj.vect[1] * n,
pi.plus.vect[2] * pi.plusj.vect[2] * n),
byrow = TRUE))
#compute marginal probabilities
n <- sum(d)
pi.iplus.vect <- rowSums(d)/n
pi.plusj.vect <- colSums(d)/n
#compute expectd values
e <- data.frame( matrix( c(pi.plus.vect[1] * pi.plusj.vect[1] * n,
pi.plus.vect[1] * pi.plusj.vect[2] * n,
pi.plus.vect[2] * pi.plusj.vect[1] * n,
pi.plus.vect[2] * pi.plusj.vect[2] * n),
byrow = TRUE))
#compute expectd values
e <- data.frame( matrix( c(pi.iplus.vect[1] * pi.plusj.vect[1] * n,
pi.iplus.vect[1] * pi.plusj.vect[2] * n,
pi.iplus.vect[2] * pi.plusj.vect[1] * n,
pi.iplus.vect[2] * pi.plusj.vect[2] * n),
byrow = TRUE))
e
colnames(e) <- colnames(d)
rownames(e) <- rownames(d)
#compute expectd values
e <- data.frame( matrix( c(pi.iplus.vect[1] * pi.plusj.vect[1] * n,
pi.iplus.vect[1] * pi.plusj.vect[2] * n,
pi.iplus.vect[2] * pi.plusj.vect[1] * n,
pi.iplus.vect[2] * pi.plusj.vect[2] * n),
byrow = TRUE, nrow =2 ))
colnames(e) <- colnames(d)
rownames(e) <- rownames(d)
e
round(e, 2)
d
e
(d-e)^2/e
chi.sq.stat = sum( (d - e) / e )
p.val = pchisq(chi.sq.stat, df = 1, lower.tail = 1)
print(sprintf('The p-value for the test is:  %0.3f', p.val))
chi.sq.stat = sum( (d - e)^2 / e )
p.val = pchisq(chi.sq.stat, df = 1, lower.tail = 1)
print(sprintf('The p-value for the test is:  %0.3f', p.val))
chisq.test(d)
chisq.test(d, correct = FALSE)
p.val = pchisq(chi.sq.stat, df = 1, lower.tail = FALSE)
print(sprintf('The p-value for the test is:  %0.3f', p.val))
chisq.test(d, correct = FALSE)
outline1 = sprintf('The chi-squared statistic is:  %0.3f', chi.sq.stat)
outline2 = sprintf('The p-value for the test is:  %0.3f', p.val)
cat(sprintf('%s\n%s', outline1, outline2))
outline1 = sprintf('The chi-squared statistic is:  %0.3e', chi.sq.stat)
outline2 = sprintf('The p-value for the test is:  %0.3f', p.val)
cat(sprintf('%s\n%s', outline1, outline2))
p1 = rep('.', 23)
p2 = rep('*', 23)
p1
p2
runif()
runif(1,0,1)
runif(1,0,1)
runif(1,0,1)
runif(1,0,1)
hist(runif(500,0,1))
mean(runif(500,0,1))
mean(runif(5000,0,1))
hist(runif(5000,0,1))
p1 = rep('.', 23)
p2 = rep('*', 23)
me = sapply(1:23, function(i) {
if( runif(1,0,1) >= 0.5) {
p1[i]
} else {
p2[i]
}
})
me
length(which(me) == '*')
length(which(me == '*'))
me = sapply(1:23, function(i) {
if( runif(1,0,1) >= 0.5) {
p1[i]
} else {
p2[i]
}
})
length(which(me == '*'))
c = sapply(1:23, function(i) {
if( runif(1,0,1) >= 0.5) {
p1[i]
} else {
c[i]
}
})
p1 = rep('.', 23)
p2 = rep('*', 23)
n = 100
mix = function(p1, p2) {
sapply(1:23, function(i) {
if( runif(1,0,1) >= 0.5) {
p1[i]
} else {
p2[i]
}
})
}
c1 = mix(p1, p2)
c2 = mix(p1, c1)
c3 = mix(p1, c2)
c3
length(which(c3 == '*'))
p1 = rep('.', 23)
p2 = rep('*', 23)
n = 100
mix = function(p1, p2) {
sapply(1:23, function(i) {
if( runif(1,0,1) >= 0.5) {
p1[i]
} else {
p2[i]
}
})
}
sapply(1:n, function(i) {
c1 = mix(p1, p2)
c2 = mix(p1, c1)
c3 = mix(p1, c2)
length(which(c3 == '*'))
})
sim = sapply(1:n, function(i) {
c1 = mix(p1, p2)
c2 = mix(p1, c1)
c3 = mix(p1, c2)
length(which(c3 == '*'))
})
length( which(sim == 0) )/n
n = 1000
p1 = rep('.', 23)
p2 = rep('*', 23)
mix = function(p1, p2) {
sapply(1:23, function(i) {
if( runif(1,0,1) >= 0.5) {
p1[i]
} else {
p2[i]
}
})
}
gen.test = function(n) {
n = 1000
sim = sapply(1:n, function(i) {
c1 = mix(p1, p2)
c2 = mix(p1, c1)
c3 = mix(p1, c2)
length(which(c3 == '*'))
})
length( which(sim == 0) )/n
}
gen.test(100)
gen.test(100)
gen.test(100)
gen.test(100)
gen.test(1000)
gen.test(1000)
gen.test(1000)
gen.test(1000)
gen.test(1000)
gen.test(1000)
gen.test(1000)
gen.test(1000000)
gen.test(1000000)
gen.test(1000000)
gen.test(1000000)
gen.test(1000000)
gen.test(1000000)
gen.test(1000000)
gen.test(1000000)
gen.test(10000000)
gen.test(10000000)
gen.test(10000000)
gen.test(10000000)
gen.test(10000000)
res = rmultinom(100,23,prob=c(.125,.875))
res
length(which(res[1,] == 0))
n=10000000
res = rmultinom(n,23,prob=c(.125,.875))
length(which(res[1,] == 0))/n
pbinom(0, 23, prob = .125, lower.tail = FALSE)
pbinom(0, 23, prob = .125)
install.packages(c("coda", "devtools", "digest", "dplyr", "epiR", "evaluate", "fansi", "ggplot2", "mime", "R6", "Rcpp", "rlang", "rstudioapi", "servr", "shiny", "tidyselect", "tinytex", "xfun"))
version()
Version()
R.Version()
R.Version()
R.version
install.package('glmnet')
install.packages('glmnet')
library(datamicroarray)
data('alon', package = 'datamicroarray')
x = as.matrix(alon$x)
y = as.matrix(alon$y)
dim(x)
dim(y)
y
y = as.factor(y)
y
glmmod = glmnet(x, y, alpha=1, family='binomial')
library(glmnet)
glmmod = glmnet(x, y, alpha=1, family='binomial')
glmmod
plot(glmmod)
plot(glmmod, xvar='lambda')
cv.glmmod = cv.glmnet(x,y,alpha=1)
cv.glmmod = cv.glmnet(x,y=as.numeric(y),alpha=1)
cv.glmmod
plot(cv.glmmod)
best.lambda = cv.glmmod$lambda.min
glmmod = glmnet(x, y, alpha=1, family='binomial', lambda = best.lambda)
coeff(glmmod)
coefficients(glmmod)
i = which(coefficients(glmmod) != 0)
i
x.red = x[,i]
dimx.red
dim(x.red)
glm.coeffs = coefficients(glmmod)[i]
glm.coeffs
glmmod.red = glmnet(x.red,y,family='binomial',alpha=1 )
coefficients(glmmod.red)
glm.red = glm(y~x.red, family='binomial')
coeff(glm.red)
coefficients(glm.red)
glm.coeffs
install.packages('imager')
install.packages('jpeg')
install.packages('jpeg')
install.packages('tiff')
install.packages('tiff')
install.packages('imager')
install.packages('imager')
install.packages('png')
install.packages('imager')
library(imager)
setwd("/storage/ColoComp/Development/NNFS")
source('/storage/ColoComp/Development/NNFS/NNFS.R')
# image from X,y
library(imager)
img = load.image('Petro.jpeg')
img.df = as.data.frame(img)
X.trn = as.matrix(img.df[,1:2])
Y.trn = as.matrix(img.df[,3], nrow=dim(img.df)[1])
nn = NNModel(input.dim = 2, layers=c(20, 20, 1),
activation=c('sigmoid', 'sigmoid', 'sigmoid'))
learning.rate = 0.1
n.epochs = 100
nn.trn = train(nn,X.trn,Y.trn, epochs=n.epochs, mini.batch.size=25, learning.rate=learning.rate)
n.epochs = 1
nn.trn = train(nn,X.trn,Y.trn, epochs=n.epochs, mini.batch.size=25, learning.rate=learning.rate)
img.prd = img.df
img.prd$value = apply(img.prd, 1, function(r) {
predict(nn, r$x, r$y)
})
img.prd = img.df
img.prd$value = apply(img.prd, 1, function(r) {
predict(nn, X=matrix(c(r$x, r$y), nrow=1))
})
img.prd = img.df
img.prd$value = apply(img.prd, 1, function(r) {
predict(nn, X=matrix(c(r[1], r$[2]), nrow=1))
})
img.prd$value = apply(img.prd, 1, function(r) {
img.prd$value = apply(img.prd, 1, function(r) {
predict(nn, X=matrix(c(r[1], r[2]), nrow=1))
})
img.prd.value
img.prd$value
img.df$value
img.prd.df = img.df
img.prd.df$value = apply(img.prd, 1, function(r) {
predict(nn, X=matrix(c(r[1], r[2]), nrow=1))
})
img.prd = as.cimg(img.prd.df)
plot(img.prd)
plog(img.df)
plot(img.df)
plot(as.cimg(img.df))
n.epochs = 10
nn.trn = train(nn,X.trn,Y.trn, epochs=n.epochs, mini.batch.size=25, learning.rate=learning.rate)
nn = NNModel(input.dim = 2, layers=c(20, 20, 1),
activation=c('sigmoid', 'sigmoid', 'sigmoid'))
learning.rate = 0.1
n.epochs = 10
nn.trn = train(nn,X.trn,Y.trn, epochs=n.epochs, mini.batch.size=25, learning.rate=learning.rate)
img.prd.df = img.df
img.prd.df$value = apply(img.prd, 1, function(r) {
predict(nn, X=matrix(c(r[1], r[2]), nrow=1))
})
img.prd = as.cimg(img.prd.df)
plot(img.prd)
img.prd.df
nn = NNModel(input.dim = 2, layers=c(20, 20, 1),
activation=c('sigmoid', 'sigmoid', 'sigmoid'))
learning.rate = 0.1
n.epochs = 10
img.prd.df = img.df
img.prd.df$value = apply(img.prd, 1, function(r) {
predict(nn, X=matrix(c(r[1], r[2]), nrow=1))
})
img.prd.df
plot(img.prd)
n.epochs = 100
nn = NNModel(input.dim = 2, layers=c(20, 20, 1),
activation=c('sigmoid', 'sigmoid', 'sigmoid'))
learning.rate = 0.1
n.epochs = 100
nn.trn = train(nn,X.trn,Y.trn, epochs=n.epochs, mini.batch.size=25, learning.rate=learning.rate)
nn.trn
nn
nn.trn
nn
img.prd.df = img.df
img.prd.df$value = apply(img.prd, 1, function(r) {
predict(nn, X=matrix(c(r[1], r[2]), nrow=1))
})
img.prd = as.cimg(img.prd.df)
plot(img.prd)
nn = NNModel(input.dim = 2, layers=c(20, 20, 1),
activation=c('leaky.relu', 'leaky.relu', 'sigmoid'))
learning.rate = 0.1
n.epochs = 10
nn.trn = train(nn,X.trn,Y.trn, epochs=n.epochs, mini.batch.size=25, learning.rate=learning.rate)
img.prd.df = img.df
img.prd.df$value = apply(img.prd, 1, function(r) {
predict(nn, X=matrix(c(r[1], r[2]), nrow=1))
})
img.prd = as.cimg(img.prd.df)
plot(img.prd)
nn = NNModel(input.dim = 2, layers=c(20, 20, 1),
activation=c('leaky.relu', 'leaky.relu', 'sigmoid'))
nn.trn = nn
img.prd.df = img.df
img.prd.df$value = apply(img.prd, 1, function(r) {
predict(nn.trn, X=matrix(c(r[1], r[2]), nrow=1))
})
img.prd = as.cimg(img.prd.df)
plot(img.prd)
nn = NNModel(input.dim = 2, layers=c(20, 20, 1),
activation=c('leaky.relu', 'leaky.relu', 'sigmoid'))
nn.trn = nn
img.prd.df = img.df
img.prd.df$value = apply(img.prd, 1, function(r) {
predict(nn.trn, X=matrix(c(r[1], r[2]), nrow=1))
})
img.prd = as.cimg(img.prd.df)
plot(img.prd)
learning.rate = 0.1
n.epochs = 10
nn.trn = train(nn,X.trn,Y.trn, epochs=n.epochs, mini.batch.size=25, learning.rate=learning.rate)
img.prd.df = img.df
img.prd.df$value = apply(img.prd, 1, function(r) {
predict(nn.trn, X=matrix(c(r[1], r[2]), nrow=1))
})
img.prd = as.cimg(img.prd.df)
plot(img.prd)
opar = par(mfrow=c(1,2))
plot(img.prd)
plot(as.cimg(img.df))
par(opar)
nn = NNModel(input.dim = 2, layers=c(20, 20, 1),
activation=c('leaky.relu', 'leaky.relu', 'sigmoid'))
learning.rate = 0.1
n.epochs = 100
nn.trn = train(nn,X.trn,Y.trn, epochs=n.epochs, mini.batch.size=25, learning.rate=learning.rate)
img.prd.df = img.df
img.prd.df$value = apply(img.prd, 1, function(r) {
predict(nn.trn, X=matrix(c(r[1], r[2]), nrow=1))
})
img.prd = as.cimg(img.prd.df)
opar = par(mfrow=c(1,2))
plot(img.prd)
plot(as.cimg(img.df))
par(opar)
nn.trn
img.prd.df$value
